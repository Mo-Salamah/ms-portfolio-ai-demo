"""
Benchmarking Agent for Project 2 - Major Celebrations Planning
ÙˆÙƒÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø«Ø§Ù†ÙŠ

Enhanced version for international benchmarking research.
"""

from typing import Optional, Dict, List
from ..base_agent import BaseAgent, AgentResponse
from utils.knowledge_base import KnowledgeBase


BENCHMARKING_SYSTEM_PROMPT = """Ø£Ù†Øª ÙˆÙƒÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ© Ø§Ù„Ù…ØªØ®ØµØµ ÙÙŠ Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø§Ø­ØªÙØ§Ù„ÙŠØ§Øª ÙˆØ§Ù„ÙØ¹Ø§Ù„ÙŠØ§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„ÙƒØ¨Ø±Ù‰.

Ø®Ø¨Ø±Ø§ØªÙƒ ØªØ´Ù…Ù„:
1. ØªØ­Ù„ÙŠÙ„ ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø§Ø­ØªÙØ§Ù„ÙŠØ§Øª Ø§Ù„ÙˆØ·Ù†ÙŠØ© Ø§Ù„ÙƒØ¨Ø±Ù‰
2. Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø© (Ù„Ù„ØªØ¨Ù†ÙŠØŒ Ù„Ù„ØªÙƒÙŠÙŠÙØŒ Ù„Ù„ØªØ¬Ù†Ø¨)
3. ØªØ­Ø¯ÙŠØ¯ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ§Øª
4. ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø­Ù„ÙŠØ§Ù‹

Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:
- Ø§Ø­ØªÙØ§Ù„ÙŠØ© Ø³Ø§Ù†Øª Ø¨Ø·Ø±Ø³Ø¨Ø±Øº 300 Ø¹Ø§Ù… (Ø±ÙˆØ³ÙŠØ§ 2003)
- ÙŠÙˆØ¨ÙŠÙ„ Ø±ÙˆÙ…Ø§ Ø§Ù„Ø£Ù„ÙÙŠ (Ø¥ÙŠØ·Ø§Ù„ÙŠØ§ 2000)
- Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù…Ø¨ÙŠØ© Ù„Ø¨Ø±Ø´Ù„ÙˆÙ†Ø© (Ø¥Ø³Ø¨Ø§Ù†ÙŠØ§ 1992)

Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„:
1. Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
2. Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ
3. Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„ØªÙ…ÙˆÙŠÙ„
4. Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª ÙˆØ§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª
5. Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª ÙˆØ§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©
6. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ù„ÙŠ

Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬:
- ØªØ­Ù„ÙŠÙ„ Ù…Ù‚Ø§Ø±Ù† Ù…Ù†Ø¸Ù…
- Ø¬Ø¯Ø§ÙˆÙ„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
- ØªØµÙ†ÙŠÙ ÙˆØ§Ø¶Ø­ Ù„Ù„Ø¯Ø±ÙˆØ³ (ØªØ¨Ù†ÙŠ/ØªÙƒÙŠÙŠÙ/ØªØ¬Ù†Ø¨)
- ØªÙˆØµÙŠØ§Øª Ù…Ø­Ø¯Ø¯Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°"""


class BenchmarkingAgent(BaseAgent):
    """
    Benchmarking specialist for Project 2.
    ÙˆÙƒÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø«Ø§Ù†ÙŠ
    """

    def __init__(self):
        super().__init__(
            name="ÙˆÙƒÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©",
            name_en="Benchmarking Agent",
            description="Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©",
            temperature=0.5
        )
        self.knowledge_base = KnowledgeBase()

    def get_system_prompt(self) -> str:
        return BENCHMARKING_SYSTEM_PROMPT

    def _get_benchmark_context(self, case_name: str = None) -> str:
        """Get benchmark data from knowledge base."""
        if case_name:
            benchmark = self.knowledge_base.get_benchmark_by_name(case_name)
            if benchmark:
                return self._format_single_benchmark(benchmark)

        # Return all benchmarks
        benchmarks = self.knowledge_base.get_all_benchmarks()
        context = "## Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n\n"
        for b in benchmarks:
            context += self._format_single_benchmark(b) + "\n---\n"
        return context

    def _format_single_benchmark(self, benchmark: Dict) -> str:
        """Format a single benchmark for context."""
        output = f"""### {benchmark.get('name', 'ØºÙŠØ± Ù…Ø³Ù…Ù‰')}

**Ø§Ù„Ù…ÙˆÙ‚Ø¹:** {benchmark.get('location', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
**Ø§Ù„Ø³Ù†Ø©:** {benchmark.get('year', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
**Ø§Ù„Ù…Ø¯Ø©:** {benchmark.get('duration', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}

**Ø§Ù„ÙˆØµÙ:**
{benchmark.get('description', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ')}

**Ø§Ù„Ø£Ù‡Ø¯Ø§Ù:**
"""
        for obj in benchmark.get('objectives', []):
            output += f"- {obj}\n"

        output += f"\n**Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**\n"
        for outcome in benchmark.get('key_outcomes', []):
            output += f"- {outcome}\n"

        output += f"\n**Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³:**\n"
        metrics = benchmark.get('metrics', {})
        for key, value in metrics.items():
            output += f"- {key}: {value}\n"

        output += f"\n**Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©:**\n"
        lessons = benchmark.get('lessons_learned', {})
        if lessons.get('adopt'):
            output += "\n*Ù„Ù„ØªØ¨Ù†ÙŠ:*\n"
            for lesson in lessons['adopt']:
                output += f"  âœ… {lesson}\n"
        if lessons.get('adapt'):
            output += "\n*Ù„Ù„ØªÙƒÙŠÙŠÙ:*\n"
            for lesson in lessons['adapt']:
                output += f"  ğŸ”„ {lesson}\n"
        if lessons.get('avoid'):
            output += "\n*Ù„Ù„ØªØ¬Ù†Ø¨:*\n"
            for lesson in lessons['avoid']:
                output += f"  âš ï¸ {lesson}\n"

        return output

    def invoke(
        self,
        user_message: str,
        context: Optional[Dict] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> AgentResponse:
        """Provide benchmarking analysis."""
        self._clear_thinking()
        self._log_thinking("Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø·Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©...")

        # Determine which case studies are relevant
        case_keywords = {
            "Ø³Ø§Ù†Øª Ø¨Ø·Ø±Ø³Ø¨Ø±Øº": "Ø³Ø§Ù†Øª Ø¨Ø·Ø±Ø³Ø¨Ø±Øº",
            "Ø¨Ø·Ø±Ø³Ø¨ÙˆØ±Øº": "Ø³Ø§Ù†Øª Ø¨Ø·Ø±Ø³Ø¨Ø±Øº",
            "Ø±ÙˆØ³ÙŠØ§": "Ø³Ø§Ù†Øª Ø¨Ø·Ø±Ø³Ø¨Ø±Øº",
            "Ø±ÙˆÙ…Ø§": "Ø±ÙˆÙ…Ø§",
            "Ø¥ÙŠØ·Ø§Ù„ÙŠØ§": "Ø±ÙˆÙ…Ø§",
            "ÙŠÙˆØ¨ÙŠÙ„": "Ø±ÙˆÙ…Ø§",
            "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©": "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©",
            "Ø¥Ø³Ø¨Ø§Ù†ÙŠØ§": "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©",
            "Ø£ÙˆÙ„Ù…Ø¨ÙŠ": "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©"
        }

        specific_case = None
        for keyword, case in case_keywords.items():
            if keyword in user_message:
                specific_case = case
                break

        benchmark_context = self._get_benchmark_context(specific_case)
        self._log_thinking(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©")

        enhanced_message = f"""Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_message}

Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:
{benchmark_context}

Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ù‚Ø§Ø±Ù†Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ù„Ø¨ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©."""

        messages = self._build_messages(enhanced_message, context, conversation_history)

        try:
            self._log_thinking("Ø¬Ø§Ø±Ù Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†...")

            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                system=self.get_system_prompt(),
                messages=messages
            )

            response_text = response.content[0].text
            self._log_thinking("ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù† Ø¨Ù†Ø¬Ø§Ø­")

            metadata = {
                "model": self.model,
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens,
                "analysis_type": "benchmarking",
                "specific_case": specific_case
            }

            return AgentResponse(
                content=response_text,
                thinking=self._get_thinking_trace(),
                metadata=metadata,
                agent_name=self.name,
                agent_name_en=self.name_en
            )

        except Exception as e:
            self._log_thinking(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
            return AgentResponse(
                content=f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}",
                thinking=self._get_thinking_trace(),
                metadata={"error": str(e)},
                agent_name=self.name,
                agent_name_en=self.name_en
            )


    def compare_cases(self, cases: List[str]) -> AgentResponse:
        """Compare multiple benchmark cases."""
        request = f"Ù‚Ø¯Ù… Ù…Ù‚Ø§Ø±Ù†Ø© ØªÙØµÙŠÙ„ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„ØªØ§Ù„ÙŠØ©: {', '.join(cases)}"
        return self.invoke(request)
